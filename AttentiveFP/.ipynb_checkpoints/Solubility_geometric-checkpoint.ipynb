{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from AttentiveFP import Fingerprint, graph_dict, graph_dataset, null_collate, Graph, Logger, time_to_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_aviable = torch.cuda.is_available()\n",
    "device = torch.device(0)\n",
    "\n",
    "SEED = 108 \n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  1128\n",
      "number of successfully processed smiles:  1128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_name = 'solubility'\n",
    "tasks = ['measured log solubility in mols per litre']\n",
    "\n",
    "raw_filename = \"../data/delaney-processed.csv\"\n",
    "feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename)\n",
    "smilesList = smiles_tasks_df.smiles.values\n",
    "print(\"number of all smiles: \", len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)].reset_index()\n",
    "smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 200\n",
    "\n",
    "p_dropout= 0.2\n",
    "fingerprint_dim = 32\n",
    "\n",
    "weight_decay = 5 # also known as l2_regularization_lambda\n",
    "learning_rate = 2.5\n",
    "K = 2\n",
    "T = 2\n",
    "per_task_output_units_num = 1 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f6dcdfd2d098>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msmiles_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmiles_tasks_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'smiles'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmiles_tasks_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgraph_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "smiles_list = smiles_tasks_df['smiles'].values\n",
    "label_list = smiles_tasks_df[tasks[0]].values\n",
    "graph_dict = graph_dict(smiles_list, label_list, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size:  226\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "train_fold = []\n",
    "valid_fold = []\n",
    "for k, (train_idx, valid_idx) in enumerate(kfold.split(smiles_list)):\n",
    "    train_fold.append(train_idx)\n",
    "    valid_fold.append(valid_idx)\n",
    "    \n",
    "# avoiding the last batch has too few samples by slightly tune the batch_size\n",
    "while (len(train_fold[0]) % batch_size) / batch_size <0.8:\n",
    "    batch_size +=1\n",
    "print(\"batch size: \", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59206\n",
      "sum_importance torch.Size([1])\n",
      "preprocess.0.linear.weight torch.Size([32, 39])\n",
      "preprocess.0.linear.bias torch.Size([32])\n",
      "preprocess.0.bn.weight torch.Size([32])\n",
      "preprocess.0.bn.bias torch.Size([32])\n",
      "propagate.0.encoder.0.linear.weight torch.Size([1024, 10])\n",
      "propagate.0.encoder.0.linear.bias torch.Size([1024])\n",
      "propagate.0.encoder.0.bn.weight torch.Size([1024])\n",
      "propagate.0.encoder.0.bn.bias torch.Size([1024])\n",
      "propagate.0.align.weight torch.Size([1, 64])\n",
      "propagate.0.align.bias torch.Size([1])\n",
      "propagate.0.attend.linear.weight torch.Size([32, 32])\n",
      "propagate.0.attend.linear.bias torch.Size([32])\n",
      "propagate.0.attend.bn.weight torch.Size([32])\n",
      "propagate.0.attend.bn.bias torch.Size([32])\n",
      "propagate.0.gru.weight_ih torch.Size([96, 32])\n",
      "propagate.0.gru.weight_hh torch.Size([96, 32])\n",
      "propagate.0.gru.bias_ih torch.Size([96])\n",
      "propagate.0.gru.bias_hh torch.Size([96])\n",
      "propagate.1.encoder.0.linear.weight torch.Size([1024, 10])\n",
      "propagate.1.encoder.0.linear.bias torch.Size([1024])\n",
      "propagate.1.encoder.0.bn.weight torch.Size([1024])\n",
      "propagate.1.encoder.0.bn.bias torch.Size([1024])\n",
      "propagate.1.align.weight torch.Size([1, 64])\n",
      "propagate.1.align.bias torch.Size([1])\n",
      "propagate.1.attend.linear.weight torch.Size([32, 32])\n",
      "propagate.1.attend.linear.bias torch.Size([32])\n",
      "propagate.1.attend.bn.weight torch.Size([32])\n",
      "propagate.1.attend.bn.bias torch.Size([32])\n",
      "propagate.1.gru.weight_ih torch.Size([96, 32])\n",
      "propagate.1.gru.weight_hh torch.Size([96, 32])\n",
      "propagate.1.gru.bias_ih torch.Size([96])\n",
      "propagate.1.gru.bias_hh torch.Size([96])\n",
      "superGather.0.align.weight torch.Size([1, 64])\n",
      "superGather.0.align.bias torch.Size([1])\n",
      "superGather.0.attend.linear.weight torch.Size([32, 32])\n",
      "superGather.0.attend.linear.bias torch.Size([32])\n",
      "superGather.0.attend.bn.weight torch.Size([32])\n",
      "superGather.0.attend.bn.bias torch.Size([32])\n",
      "superGather.0.gru.weight_ih torch.Size([96, 32])\n",
      "superGather.0.gru.weight_hh torch.Size([96, 32])\n",
      "superGather.0.gru.bias_ih torch.Size([96])\n",
      "superGather.0.gru.bias_hh torch.Size([96])\n",
      "superGather.1.align.weight torch.Size([1, 64])\n",
      "superGather.1.align.bias torch.Size([1])\n",
      "superGather.1.attend.linear.weight torch.Size([32, 32])\n",
      "superGather.1.attend.linear.bias torch.Size([32])\n",
      "superGather.1.attend.bn.weight torch.Size([32])\n",
      "superGather.1.attend.bn.bias torch.Size([32])\n",
      "superGather.1.gru.weight_ih torch.Size([96, 32])\n",
      "superGather.1.gru.weight_hh torch.Size([96, 32])\n",
      "superGather.1.gru.bias_ih torch.Size([96])\n",
      "superGather.1.gru.bias_hh torch.Size([96])\n",
      "predict.0.linear.weight torch.Size([32, 32])\n",
      "predict.0.linear.bias torch.Size([32])\n",
      "predict.0.bn.weight torch.Size([32])\n",
      "predict.0.bn.bias torch.Size([32])\n",
      "predict.3.weight torch.Size([1, 32])\n",
      "predict.3.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(output_units_num, fingerprint_dim, K=K, T=T, p_dropout=p_dropout)\n",
    "model.to(device)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "# optimizer = optim.SGD(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "\n",
    "# model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in  model.parameters()])\n",
    "print(params)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(smiles_list):\n",
    "    model.train()\n",
    "    train_loader = DataLoader(graph_dataset(smiles_list, graph_dict), batch_size, collate_fn=null_collate, \\\n",
    "                              num_workers=8, pin_memory=True, shuffle=True, worker_init_fn=np.random.seed(SEED))\n",
    "    losses = []\n",
    "    for b, (smiles, atom, bond, bond_index, mol_index, label) in enumerate(train_loader):\n",
    "        atom = atom.to(device)\n",
    "        bond = bond.to(device)\n",
    "        bond_index = bond_index.to(device)\n",
    "        mol_index = mol_index.to(device)\n",
    "        label = label.to(device)\n",
    "        mol_prediction = model(atom, bond, bond_index, mol_index)\n",
    "        loss = loss_function(mol_prediction, label.view(-1,1))     \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "def eval(smiles_list):\n",
    "    model.eval()\n",
    "    eval_MAE_list = []\n",
    "    eval_MSE_list = []\n",
    "    eval_loader = DataLoader(graph_dataset(smiles_list, graph_dict), batch_size, collate_fn=null_collate, \\\n",
    "                              num_workers=8, pin_memory=True, shuffle=False, worker_init_fn=np.random.seed(SEED))\n",
    "    for b, (smiles, atom, bond, bond_index, mol_index, label) in enumerate(eval_loader):\n",
    "        atom = atom.to(device)\n",
    "        bond = bond.to(device)\n",
    "        bond_index = bond_index.to(device)\n",
    "        mol_index = mol_index.to(device)\n",
    "        label = label.to(device)\n",
    "        mol_prediction = model(atom, bond, bond_index, mol_index)\n",
    "        MAE = F.l1_loss(mol_prediction, label.view(-1,1), reduction='none')        \n",
    "        MSE = F.mse_loss(mol_prediction, label.view(-1,1), reduction='none')\n",
    "        eval_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        eval_MSE_list.extend(MSE.data.squeeze().cpu().numpy())\n",
    "    return np.array(eval_MAE_list).mean(), np.array(eval_MSE_list).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch | loss | train MSE |  valid MSE |  time \n",
      "  0   | 12.5310 | 10.4388 | 8.7116  |  0 min 03 sec \n",
      "  1   | 9.5659  | 3.4905  | 2.5679  |  0 min 05 sec \n",
      "  2   | 7.9051  | 7.7713  | 6.4416  |  0 min 08 sec \n",
      "  3   | 6.4782  | 13.7280 | 11.8362 |  0 min 10 sec \n",
      "  4   | 5.3475  | 15.3932 | 13.4750 |  0 min 13 sec \n",
      "  5   | 4.4454  | 11.3295 | 9.6337  |  0 min 16 sec \n",
      "  6   | 3.5963  | 10.1027 | 8.7187  |  0 min 19 sec \n",
      "  7   | 2.9854  | 5.3952  | 4.5197  |  0 min 21 sec \n",
      "  8   | 2.3347  | 5.5308  | 4.9677  |  0 min 25 sec \n",
      "  9   | 1.8840  | 2.1873  | 1.7569  |  0 min 27 sec \n",
      " 10   | 1.5357  | 1.3596  | 1.2669  |  0 min 30 sec \n",
      " 11   | 1.1801  | 0.8639  | 0.8587  |  0 min 33 sec \n",
      " 12   | 1.0637  | 0.6349  | 0.6794  |  0 min 36 sec \n",
      " 13   | 0.8225  | 0.5611  | 0.6214  |  0 min 38 sec \n",
      " 14   | 0.8218  | 0.5196  | 0.5521  |  0 min 41 sec \n",
      " 15   | 0.7818  | 0.4651  | 0.4886  |  0 min 44 sec \n",
      " 16   | 0.7070  | 0.4653  | 0.5193  |  0 min 47 sec \n",
      " 17   | 0.7476  | 0.4138  | 0.4522  |  0 min 49 sec \n",
      " 18   | 0.7563  | 0.4108  | 0.5235  |  0 min 52 sec \n",
      " 19   | 0.7142  | 0.3683  | 0.4666  |  0 min 55 sec \n",
      " 20   | 0.6822  | 0.3927  | 0.4662  |  0 min 57 sec \n",
      " 21   | 0.6224  | 0.3698  | 0.4712  |  1 min 00 sec \n",
      " 22   | 0.6890  | 0.3184  | 0.4604  |  1 min 03 sec \n",
      " 23   | 0.5927  | 0.3009  | 0.4357  |  1 min 06 sec \n",
      " 24   | 0.6508  | 0.3486  | 0.4753  |  1 min 08 sec \n",
      " 25   | 0.6261  | 0.3133  | 0.4359  |  1 min 11 sec \n",
      " 26   | 0.6124  | 0.3145  | 0.4135  |  1 min 13 sec \n",
      " 27   | 0.6186  | 0.3157  | 0.4812  |  1 min 16 sec \n",
      " 28   | 0.6042  | 0.2863  | 0.4213  |  1 min 19 sec \n"
     ]
    }
   ],
   "source": [
    "\n",
    "log = Logger()\n",
    "log.open(f'log/{prefix_filename}_{start_time}.txt')\n",
    "\n",
    "f = '{:^5} | {:^7.4f} | {:^7.4f} | {:^7.4f} | {:^7} \\n'\n",
    "log.write('epoch | loss | train MSE |  valid MSE |  time \\n')\n",
    "start = timer()\n",
    "\n",
    "log2 = Logger()\n",
    "log2.open(f'{prefix_filename}_best_{start_time}.txt')\n",
    "f2 = '{:^5} | {:^5} | {:^7.4f} | {:^7.4f} \\n'\n",
    "\n",
    "for fold_index in range(1):\n",
    "    \n",
    "    model = Fingerprint(output_units_num, fingerprint_dim, K=K, T=T, p_dropout=p_dropout)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "    \n",
    "    best_param ={}\n",
    "    best_param[\"train_epoch\"] = 0\n",
    "    best_param[\"valid_epoch\"] = 0\n",
    "    best_param[\"train_MSE\"] = 800\n",
    "    best_param[\"valid_MSE\"] = 800\n",
    "    for epoch in range(100):\n",
    "        losses = train(smiles_list[train_fold[fold_index]])\n",
    "        traine_MAE, train_MSE = eval(smiles_list[train_fold[fold_index]])\n",
    "        valid_MAE, valid_MSE = eval(smiles_list[valid_fold[fold_index]])\n",
    "        \n",
    "        \n",
    "        timing = time_to_str((timer() - start), 'sec')  \n",
    "        log.write(f.format(epoch, losses, train_MSE, valid_MSE, timing))\n",
    "        \n",
    "        if train_MSE < best_param[\"train_MSE\"]:\n",
    "            best_param[\"train_epoch\"] = epoch\n",
    "            best_param[\"train_MSE\"] = train_MSE\n",
    "        if valid_MSE < best_param[\"valid_MSE\"]:\n",
    "            best_param[\"valid_epoch\"] = epoch\n",
    "            best_param[\"valid_MSE\"] = valid_MSE\n",
    "        # Early Stopping internal code!\n",
    "        if (epoch - best_param[\"train_epoch\"] >10) and (epoch - best_param[\"valid_epoch\"] >18):        \n",
    "            break\n",
    "\n",
    "    log2.write('fold | epoch | train_MSE | valid MSE \\n')\n",
    "    log2.write(f2.format(fold_index, best_param[\"valid_epoch\"],best_param[\"train_MSE\"],best_param[\"valid_MSE\"]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best val rmse: 0.5748921\n"
     ]
    }
   ],
   "source": [
    "print('best val rmse:',np.sqrt(best_param[\"valid_MSE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
